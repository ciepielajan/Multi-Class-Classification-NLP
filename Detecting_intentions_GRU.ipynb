{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detecting_intentions_MLP",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOoyHaJ5ELpm4jtoVDs9Ow7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ciepielajan/Multi-Class-Classification-NLP/blob/main/Detecting_intentions_GRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us7PJ6w-n8ge"
      },
      "source": [
        "#### Pobranie danych"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZ_7ET22CAsA",
        "outputId": "3e141bcc-4aeb-4dab-9928-c56968e22226"
      },
      "source": [
        "# https://drive.google.com/file/d/1fI6EXyD9TMTC1jzdu206ljXOGNjdHprq/view?usp=sharing\n",
        "!gdown --id \"1fI6EXyD9TMTC1jzdu206ljXOGNjdHprq\""
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1fI6EXyD9TMTC1jzdu206ljXOGNjdHprq\n",
            "To: /content/user_intent.zip\n",
            "\r  0% 0.00/271k [00:00<?, ?B/s]\r100% 271k/271k [00:00<00:00, 62.8MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWusnzuPCHqv",
        "outputId": "3066baff-8720-4604-80de-5e99f501225d"
      },
      "source": [
        "!unzip \"user_intent.zip\""
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  user_intent.zip\n",
            "replace train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CI1LZgj-Kin"
      },
      "source": [
        ""
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUKeVYWfCOdU"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "data_set_train = pd.read_csv(\"train.csv\")\n",
        "data_set_valid = pd.read_csv(\"validation.csv\")\n",
        "\n",
        "print(data_set_train.shape)\n",
        "print(data_set_valid.shape)\n",
        "\n",
        "print(data_set_train.columns)\n",
        "print(data_set_valid.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Vg1fqbGoCrp"
      },
      "source": [
        "#### Podstawowy process text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GQNuCjSlz0F"
      },
      "source": [
        "import re\n",
        "def process_text(sentence):\n",
        "    sentence = re.sub('[A-Za-z0-9]+@[a-zA-z].[a-zA-Z]+', '', sentence)  # maile\n",
        "    sentence = re.sub('(http[s]*:[/][/])[a-zA-Z0-9]+', '', sentence)  # linki\n",
        "    sentence = re.sub(r\"<[^>]+>\", \" \", sentence) # remove html tag\n",
        "    sentence = re.sub(r\"[^a-zA-Z\\s]\", \"\", sentence)  # remove punctuations and numbers   \n",
        "    sentence = re.sub(r\"\\b[A-Za-z]{1}\\b\", \"\", sentence)  # remove single characters\n",
        "\n",
        "    sentence = re.sub(\"^\\s+|\\s+$\", \"\", sentence, flags=re.UNICODE) # Remove spaces both in the BEGINNING and in the END of a string:\n",
        "    sentence = \" \".join(re.split(\"\\s+\", sentence, flags=re.UNICODE))  # Remove ONLY DUPLICATE spaces:\n",
        "    sentence = sentence.lower()\n",
        "    \n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZJOju1sFOwp"
      },
      "source": [
        "data_set_train[\"clean_text\"] = data_set_train[\"text\"].apply(lambda x: process_text(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7epaW5cXoXef"
      },
      "source": [
        "#### `LabelEncoder` oraz `to_categorical`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "022rNoaL-xbl"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical \n",
        "\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "data_set_train[\"labelencoder\"] = labelencoder.fit_transform(data_set_train[\"label\"])\n",
        "\n",
        "dummy_y = to_categorical(data_set_train[\"labelencoder\"], dtype =\"float32\")\n",
        "\n",
        "data_set_train[[\"clean_text\",\"label\",\"labelencoder\"]].head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RfsD1LSpSag"
      },
      "source": [
        "dummy_y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4dq1macoeQC"
      },
      "source": [
        "id_intention = 6\n",
        "print(\"Sprawdzenie poprawności LabelEncoder i to_categorical \\n\")\n",
        "print(\"Label - \", data_set_train[\"label\"].iloc[id_intention])\n",
        "print(\"LabelEncoder - \", data_set_train[\"labelencoder\"].iloc[id_intention])\n",
        "print()\n",
        "print(\"to_categorical - \", dummy_y[id_intention])\n",
        "print()\n",
        "print(\"return to LabelEncoder - \",np.argmax(dummy_y[id_intention], axis=-1))\n",
        "print(\"return to Label - \",labelencoder.inverse_transform([np.argmax(dummy_y[id_intention], axis=-1)]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lZTDFgGoSmT"
      },
      "source": [
        "#### Zdefiniowanie X i y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWd9mEjfBAS2"
      },
      "source": [
        "X = data_set_train[\"clean_text\"]\n",
        "y = dummy_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jUlcX2npzFs"
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mS_l8wZoO2R"
      },
      "source": [
        "#### Podział zbioru "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A18D02x5sjFd"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_xH9XIGuYCG"
      },
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DR0gkd1_Uv0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chWlDg9Mtmya"
      },
      "source": [
        "#### `Tokenizer` i `pad_sequences`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCm-rbaus6QG"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-ihmlc-s6QG"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "maxlen = 7\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "X_train = pad_sequences(X_train, padding=\"post\", truncating=\"post\", maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding=\"post\", truncating=\"post\", maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaRWehbu_VCe"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, SimpleRNN, Dense\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHakANxM9lOb"
      },
      "source": [
        "#### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xCHiM6a9nEv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIvlVQnasO3C"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100, input_length=maxlen))  \n",
        "model.add(GRU(128)) \n",
        "model.add(Dense(7, activation=\"softmax\"))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "print(model.summary())\n",
        "\n",
        "EarlyStop = EarlyStopping(monitor='val_loss', \n",
        "                          patience=5,\n",
        "                          verbose=1)\n",
        "\n",
        "history = model.fit(X_train, \n",
        "                    y_train, \n",
        "                    epochs=20, \n",
        "                    batch_size=64, \n",
        "                    validation_split=0.2, \n",
        "                    callbacks = [EarlyStop] )\n",
        "scores = model.evaluate(X_test, y_test)\n",
        "print(f\"Accuracy {scores[1] * 100}\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHv6PlrGrYUr"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Dokladnosc trenowania')\n",
        "plt.plot(epochs, val_acc, 'b', label='Dokladnosc walidacji')\n",
        "plt.title('Dokladnosc trenowania i walidacji')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Strata trenowania')\n",
        "plt.plot(epochs, val_loss, 'b', label='Strata walidacji')\n",
        "plt.title('Strata trenowania i walidacji')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ui9nW3K0_0bf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJtnYTgA_06S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0IdSKiJtzgd"
      },
      "source": [
        "#### Predykcja na zbiorze validacyjnym"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27dr_LCO_1IW"
      },
      "source": [
        "# oczysczenie danych\n",
        "data_set_valid[\"clean_text\"] = data_set_valid[\"text\"].apply(lambda x: process_text(x))\n",
        "\n",
        "# labelencoder \n",
        "data_set_valid[\"labelencoder\"] = labelencoder.fit_transform(data_set_valid[\"label\"])\n",
        "\n",
        "# tokenizacja weg przetrenowanego już tokenizera\n",
        "X_validate = tokenizer.texts_to_sequences(data_set_valid[\"clean_text\"])\n",
        "\n",
        "# pad sequel\n",
        "X_validate = pad_sequences(X_validate, padding=\"post\", truncating=\"post\", maxlen=maxlen)\n",
        "X_validate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOPVqktyANNF"
      },
      "source": [
        "dummy_y_valid = data_set_valid[\"labelencoder\"].values\n",
        "dummy_y_valid[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAiFC304APqL"
      },
      "source": [
        "# Sprawdzenie rozmiaru zbiorów validacyjnego\n",
        "X_validate.shape, dummy_y_valid.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRbEdb7AAXGy"
      },
      "source": [
        "predicted_lstm_val = np.argmax(model.predict(X_validate), axis=-1)\n",
        "predicted_lstm_val[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5wZwn-_uKE9"
      },
      "source": [
        "#### Rozkodowanie przewidzianych i prawidłowych etykiet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4U9hYvnBJ9F"
      },
      "source": [
        "y_pred = labelencoder.inverse_transform(predicted_lstm_val)\n",
        "y_pred = pd.Series(y_pred)\n",
        "y_pred.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW03pUanA729"
      },
      "source": [
        "y_val = labelencoder.inverse_transform(dummy_y_valid)\n",
        "y_val = pd.Series(y_val)\n",
        "y_val.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcGfyRgQudTZ"
      },
      "source": [
        "#### `Confusion matrix`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXVwswIsA9RT"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGr6-cjzBFLc"
      },
      "source": [
        "classes = np.unique(y_val)\n",
        "\n",
        "print('Accuracy:', round(accuracy_score(y_val, y_pred),2))\n",
        "print('F1_score:', round(f1_score(y_val, y_pred, average='weighted'),2))\n",
        "\n",
        "print(classification_report(y_val, y_pred))\n",
        "# Plot confusion matrix\n",
        "cm = confusion_matrix(y_val, y_pred)\n",
        "fig, ax = plt.subplots()\n",
        "sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, cbar=False)\n",
        "ax.set(xlabel='Pred', ylabel='True', xticklabels=classes, yticklabels=classes, title='Confusion matrix')\n",
        "plt.yticks(rotation=0)\n",
        "plt.xticks(rotation=90)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uxfqF9uum32"
      },
      "source": [
        "#### Zapoznanie się z błędnymi predykcjami "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28QYnOPM-mJz"
      },
      "source": [
        "indexes = []\n",
        "for i, phrase in enumerate(y_pred):\n",
        "  if phrase == 'SearchCreativeWork':\n",
        "    if y_val[i] == 'SearchScreeningEvent':\n",
        "      indexes.append(i)\n",
        "print(indexes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouy1yzy8-048"
      },
      "source": [
        "for i in indexes:\n",
        "  print(f\"----------------------------\\nTekst komendy:\\n{data_set_valid['text'][i]}\")\n",
        "  print(f\"Oczyszczona komenda:\\n{data_set_valid['clean_text'][i]}\")\n",
        "  print(f'True category: {y_val[i]}')\n",
        "  print(f'Predicted category: {y_pred[i]}')\n",
        "  print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lm61MY9CSpLm"
      },
      "source": [
        "Wnioski:\n",
        ">  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMBc1uV8-yLJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}