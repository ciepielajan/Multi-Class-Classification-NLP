{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detecting_intentions_CNN_KerasClassifier_i_GridSearchCrossValidation",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO16Hm2Y/l1khS5T31NvF11",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ciepielajan/Multi-Class-Classification-NLP/blob/main/Detecting_intentions_CNN_KerasClassifier_i_GridSearchCrossValidation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fImOu-ux11_s"
      },
      "source": [
        "KerasClassifier i Grid Search Cross Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us7PJ6w-n8ge"
      },
      "source": [
        "#### Pobranie danych"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZ_7ET22CAsA",
        "outputId": "8de0b0b0-3f1a-4fe2-a998-e1584b6aeac4"
      },
      "source": [
        "# https://drive.google.com/file/d/1fI6EXyD9TMTC1jzdu206ljXOGNjdHprq/view?usp=sharing\n",
        "!gdown --id \"1fI6EXyD9TMTC1jzdu206ljXOGNjdHprq\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1fI6EXyD9TMTC1jzdu206ljXOGNjdHprq\n",
            "To: /content/user_intent.zip\n",
            "\r  0% 0.00/271k [00:00<?, ?B/s]\r100% 271k/271k [00:00<00:00, 82.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWusnzuPCHqv",
        "outputId": "ff9a7902-dbc2-412d-b465-75f2dc9140e6"
      },
      "source": [
        "!unzip \"user_intent.zip\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  user_intent.zip\n",
            "  inflating: train.csv               \n",
            "  inflating: __MACOSX/._train.csv    \n",
            "  inflating: validation.csv          \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CI1LZgj-Kin"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUKeVYWfCOdU",
        "outputId": "24b61047-1d5f-4fa7-f439-7460b73e9e48"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "data_set_train = pd.read_csv(\"train.csv\")\n",
        "data_set_valid = pd.read_csv(\"validation.csv\")\n",
        "\n",
        "print(data_set_train.shape)\n",
        "print(data_set_valid.shape)\n",
        "\n",
        "print(data_set_train.columns)\n",
        "print(data_set_valid.columns)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(13784, 2)\n",
            "(700, 2)\n",
            "Index(['text', 'label'], dtype='object')\n",
            "Index(['text', 'label'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Vg1fqbGoCrp"
      },
      "source": [
        "#### Podstawowy process text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GQNuCjSlz0F"
      },
      "source": [
        "import re\n",
        "def process_text(sentence):\n",
        "    sentence = re.sub('[A-Za-z0-9]+@[a-zA-z].[a-zA-Z]+', '', sentence)  # maile\n",
        "    sentence = re.sub('(http[s]*:[/][/])[a-zA-Z0-9]+', '', sentence)  # linki\n",
        "    sentence = re.sub(r\"<[^>]+>\", \" \", sentence) # remove html tag\n",
        "    sentence = re.sub(r\"[^a-zA-Z\\s]\", \"\", sentence)  # remove punctuations and numbers   \n",
        "    sentence = re.sub(r\"\\b[A-Za-z]{1}\\b\", \"\", sentence)  # remove single characters\n",
        "\n",
        "    sentence = re.sub(\"^\\s+|\\s+$\", \"\", sentence, flags=re.UNICODE) # Remove spaces both in the BEGINNING and in the END of a string:\n",
        "    sentence = \" \".join(re.split(\"\\s+\", sentence, flags=re.UNICODE))  # Remove ONLY DUPLICATE spaces:\n",
        "    sentence = sentence.lower()\n",
        "    \n",
        "    return sentence"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZJOju1sFOwp"
      },
      "source": [
        "data_set_train[\"clean_text\"] = data_set_train[\"text\"].apply(lambda x: process_text(x))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7epaW5cXoXef"
      },
      "source": [
        "#### `LabelEncoder` oraz `to_categorical`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "022rNoaL-xbl",
        "outputId": "75d9fb03-f5b9-4538-a792-ab4e98a421b5"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical \n",
        "\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "data_set_train[\"labelencoder\"] = labelencoder.fit_transform(data_set_train[\"label\"])\n",
        "\n",
        "dummy_y = to_categorical(data_set_train[\"labelencoder\"], dtype =\"float32\")\n",
        "\n",
        "data_set_train[[\"clean_text\",\"label\",\"labelencoder\"]].head(5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "      <th>label</th>\n",
              "      <th>labelencoder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>find cinema nearest for films</td>\n",
              "      <td>SearchScreeningEvent</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>give the current series two stars</td>\n",
              "      <td>RateBook</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>find the good girl at movie house</td>\n",
              "      <td>SearchScreeningEvent</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>please make reservations for three at kosher t...</td>\n",
              "      <td>BookRestaurant</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>what is the forecast for here one second from now</td>\n",
              "      <td>GetWeather</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          clean_text  ... labelencoder\n",
              "0                      find cinema nearest for films  ...            6\n",
              "1                  give the current series two stars  ...            4\n",
              "2                  find the good girl at movie house  ...            6\n",
              "3  please make reservations for three at kosher t...  ...            1\n",
              "4  what is the forecast for here one second from now  ...            2\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RfsD1LSpSag",
        "outputId": "9eabded1-ba67-462a-95fb-3f342c49e67f"
      },
      "source": [
        "dummy_y.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13784, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4dq1macoeQC",
        "outputId": "8b660f2c-c4f1-47a2-c08f-168701849f7e"
      },
      "source": [
        "id_intention = 6\n",
        "print(\"Sprawdzenie poprawności LabelEncoder i to_categorical \\n\")\n",
        "print(\"Label - \", data_set_train[\"label\"].iloc[id_intention])\n",
        "print(\"LabelEncoder - \", data_set_train[\"labelencoder\"].iloc[id_intention])\n",
        "print()\n",
        "print(\"to_categorical - \", dummy_y[id_intention])\n",
        "print()\n",
        "print(\"return to LabelEncoder - \",np.argmax(dummy_y[id_intention], axis=-1))\n",
        "print(\"return to Label - \",labelencoder.inverse_transform([np.argmax(dummy_y[id_intention], axis=-1)]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sprawdzenie poprawności LabelEncoder i to_categorical \n",
            "\n",
            "Label -  BookRestaurant\n",
            "LabelEncoder -  1\n",
            "\n",
            "to_categorical -  [0. 1. 0. 0. 0. 0. 0.]\n",
            "\n",
            "return to LabelEncoder -  1\n",
            "return to Label -  ['BookRestaurant']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lZTDFgGoSmT"
      },
      "source": [
        "#### Zdefiniowanie X i y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWd9mEjfBAS2"
      },
      "source": [
        "X = data_set_train[\"clean_text\"]\n",
        "y = dummy_y"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jUlcX2npzFs",
        "outputId": "36bd5c6d-5184-4264-ef84-96179551052b"
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13784,), (13784, 7))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UAQ4RNONmda"
      },
      "source": [
        "\n",
        "#### `KerasClassifier` i `Grid Search Cross Validation`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vioWd2xMxru"
      },
      "source": [
        "`Grid Search Cross Validation`\n",
        "\n",
        "Tworzy siatkę nad przestrzenią wyszukiwania i ocenia model pod kątem wszystkich możliwych hiperparametrów w przestrzeni. Dobre w tym sensie, że jest proste i wyczerpujące. Z drugiej strony, może to być zbyt kosztowne w czasie obliczeń, jeśli przestrzeń poszukiwań jest duża (np. Bardzo wiele hiperparametrów).\n",
        "\n",
        "Przykład do zastosowania: https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A18D02x5sjFd"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCm-rbaus6QG"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaRWehbu_VCe"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hwih4PgGsS9k"
      },
      "source": [
        "from keras.layers import Dense, Activation, Embedding, Flatten, GlobalMaxPooling1D, Dropout, Conv1D"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnfPMuzQ-Cnq"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOcctLFPuKoa"
      },
      "source": [
        "def create_model(num_filters, kernel_size, vocab_size, embedding_dim, maxlen):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
        "    model.add(Conv1D(num_filters, kernel_size, activation='relu'))\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "    model.add(Dense(7, activation=\"softmax\")) \n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4tXfrhOxi7E",
        "outputId": "cc9f9655-ea49-4a62-c1ba-368c509230cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "%%time\n",
        "\n",
        "# df z wynikami wszystkich RandomizedSearchCV\n",
        "wyniki = pd.DataFrame()\n",
        "wyniki\n",
        "\n",
        "from keras.wrappers.scikit_learn import KerasClassifier  \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "# Main settings\n",
        "# epochs = 20\n",
        "# embedding_dim = 100\n",
        "maxlen = 13\n",
        "\n",
        "# Run grid search for each source (yelp, amazon, imdb)\n",
        "# for source, frame in df.groupby('source'):\n",
        "# print('Running grid search for data set :', source)\n",
        "sentences = data_set_train[\"clean_text\"].values  \n",
        "y = dummy_y\n",
        "\n",
        "# Train-test split\n",
        "sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, y, test_size=0.25, random_state=1000)\n",
        "\n",
        "# Tokenize words\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(sentences_train)\n",
        "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
        "X_test = tokenizer.texts_to_sequences(sentences_test)\n",
        "\n",
        "# Adding 1 because of reserved 0 index\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Pad sequences with zeros\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
        "\n",
        "# Parameter grid for grid search\n",
        "param_grid = dict(num_filters=[32, 64, 128],\n",
        "                  kernel_size=[3, 5, 7],\n",
        "                  vocab_size=[vocab_size],\n",
        "                  embedding_dim=[100,200],\n",
        "                  maxlen=[maxlen],\n",
        "                  epochs = [30],   \n",
        "                  batch_size=[16,32,64]  \n",
        "                  )\n",
        "\n",
        "\n",
        "model = KerasClassifier(build_fn=create_model,verbose=False)\n",
        "\n",
        "grid = GridSearchCV(estimator=model , param_grid=param_grid, n_jobs=-1, cv=3, verbose=10)\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "# Define early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "grid_result = grid.fit(X_train, y_train, validation_split=0.2, callbacks=[early_stopping]) \n",
        "\n",
        "# Evaluate testing set\n",
        "test_accuracy = grid.score(X_test, y_test)\n",
        "grid_result.best_params_.update({\"best_score_\":grid_result.best_score_})\n",
        "wyniki = wyniki.append(grid_result.best_params_, ignore_index=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  5.2min\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  7.4min\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed: 11.4min\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed: 15.6min\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 23.7min\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed: 32.7min\n",
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed: 42.6min\n",
            "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed: 46.6min\n",
            "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed: 51.4min\n",
            "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed: 59.0min\n",
            "[Parallel(n_jobs=-1)]: Done 109 tasks      | elapsed: 69.6min\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed: 73.9min\n",
            "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed: 79.6min\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed: 87.8min\n",
            "[Parallel(n_jobs=-1)]: Done 162 out of 162 | elapsed: 90.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 27s, sys: 5.05 s, total: 1min 32s\n",
            "Wall time: 1h 30min 57s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY4eRsph6B7p",
        "outputId": "6705ac6d-5116-4b98-e973-d4f2bbd3c171",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "wyniki"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>batch_size</th>\n",
              "      <th>best_score_</th>\n",
              "      <th>embedding_dim</th>\n",
              "      <th>epochs</th>\n",
              "      <th>kernel_size</th>\n",
              "      <th>maxlen</th>\n",
              "      <th>num_filters</th>\n",
              "      <th>vocab_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>64.0</td>\n",
              "      <td>0.983169</td>\n",
              "      <td>200.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>9462.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   batch_size  best_score_  embedding_dim  ...  maxlen  num_filters  vocab_size\n",
              "0        64.0     0.983169          200.0  ...    13.0        128.0      9462.0\n",
              "\n",
              "[1 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbCHbcCi6B7q",
        "outputId": "2c06b550-15bd-48a9-9d54-aacdcfa4aa05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"#### GridSearchCV\")\n",
        "print()\n",
        "print(\"param_grid:\")\n",
        "print(param_grid)\n",
        "print()\n",
        "print(wyniki.to_markdown())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#### GridSearchCV\n",
            "\n",
            "param_grid:\n",
            "{'num_filters': [32, 64, 128], 'kernel_size': [3, 5, 7], 'vocab_size': [9462], 'embedding_dim': [100, 200], 'maxlen': [13], 'epochs': [30], 'batch_size': [16, 32, 64]}\n",
            "\n",
            "|    |   batch_size |   best_score_ |   embedding_dim |   epochs |   kernel_size |   maxlen |   num_filters |   vocab_size |\n",
            "|---:|-------------:|--------------:|----------------:|---------:|--------------:|---------:|--------------:|-------------:|\n",
            "|  0 |           64 |      0.983169 |             200 |       30 |             3 |       13 |           128 |         9462 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0IdSKiJtzgd"
      },
      "source": [
        "#### Predykcja na zbiorze validacyjnym"
      ]
    }
  ]
}
