{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detecting_intentions_MLP",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMWnVdxysNEV5ZIABtdqdho",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ciepielajan/Multi-Class-Classification-NLP/blob/main/Detecting_intentions_CNN_KerasClassifier_i_GridSearchCrossValidation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fImOu-ux11_s"
      },
      "source": [
        "KerasClassifier i Grid Search Cross Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us7PJ6w-n8ge"
      },
      "source": [
        "#### Pobranie danych"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZ_7ET22CAsA",
        "outputId": "28dcb159-985e-405f-fff5-e91b84acd278"
      },
      "source": [
        "# https://drive.google.com/file/d/1fI6EXyD9TMTC1jzdu206ljXOGNjdHprq/view?usp=sharing\n",
        "!gdown --id \"1fI6EXyD9TMTC1jzdu206ljXOGNjdHprq\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1fI6EXyD9TMTC1jzdu206ljXOGNjdHprq\n",
            "To: /content/user_intent.zip\n",
            "\r  0% 0.00/271k [00:00<?, ?B/s]\r100% 271k/271k [00:00<00:00, 37.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWusnzuPCHqv",
        "outputId": "cd97b5fe-5966-4f6a-f333-81931d89c35d"
      },
      "source": [
        "!unzip \"user_intent.zip\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  user_intent.zip\n",
            "  inflating: train.csv               \n",
            "  inflating: __MACOSX/._train.csv    \n",
            "  inflating: validation.csv          \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CI1LZgj-Kin"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUKeVYWfCOdU",
        "outputId": "c963d081-2b9b-4b89-e2fb-ae3a7e835cad"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "data_set_train = pd.read_csv(\"train.csv\")\n",
        "data_set_valid = pd.read_csv(\"validation.csv\")\n",
        "\n",
        "print(data_set_train.shape)\n",
        "print(data_set_valid.shape)\n",
        "\n",
        "print(data_set_train.columns)\n",
        "print(data_set_valid.columns)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(13784, 2)\n",
            "(700, 2)\n",
            "Index(['text', 'label'], dtype='object')\n",
            "Index(['text', 'label'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Vg1fqbGoCrp"
      },
      "source": [
        "#### Podstawowy process text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GQNuCjSlz0F"
      },
      "source": [
        "import re\n",
        "def process_text(sentence):\n",
        "    sentence = re.sub('[A-Za-z0-9]+@[a-zA-z].[a-zA-Z]+', '', sentence)  # maile\n",
        "    sentence = re.sub('(http[s]*:[/][/])[a-zA-Z0-9]+', '', sentence)  # linki\n",
        "    sentence = re.sub(r\"<[^>]+>\", \" \", sentence) # remove html tag\n",
        "    sentence = re.sub(r\"[^a-zA-Z\\s]\", \"\", sentence)  # remove punctuations and numbers   \n",
        "    sentence = re.sub(r\"\\b[A-Za-z]{1}\\b\", \"\", sentence)  # remove single characters\n",
        "\n",
        "    sentence = re.sub(\"^\\s+|\\s+$\", \"\", sentence, flags=re.UNICODE) # Remove spaces both in the BEGINNING and in the END of a string:\n",
        "    sentence = \" \".join(re.split(\"\\s+\", sentence, flags=re.UNICODE))  # Remove ONLY DUPLICATE spaces:\n",
        "    sentence = sentence.lower()\n",
        "    \n",
        "    return sentence"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZJOju1sFOwp"
      },
      "source": [
        "data_set_train[\"clean_text\"] = data_set_train[\"text\"].apply(lambda x: process_text(x))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7epaW5cXoXef"
      },
      "source": [
        "#### `LabelEncoder` oraz `to_categorical`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "022rNoaL-xbl",
        "outputId": "ad8cb3c3-21d8-430f-b19d-9f16600a0f4b"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical \n",
        "\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "data_set_train[\"labelencoder\"] = labelencoder.fit_transform(data_set_train[\"label\"])\n",
        "\n",
        "dummy_y = to_categorical(data_set_train[\"labelencoder\"], dtype =\"float32\")\n",
        "\n",
        "data_set_train[[\"clean_text\",\"label\",\"labelencoder\"]].head(5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "      <th>label</th>\n",
              "      <th>labelencoder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>find cinema nearest for films</td>\n",
              "      <td>SearchScreeningEvent</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>give the current series two stars</td>\n",
              "      <td>RateBook</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>find the good girl at movie house</td>\n",
              "      <td>SearchScreeningEvent</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>please make reservations for three at kosher t...</td>\n",
              "      <td>BookRestaurant</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>what is the forecast for here one second from now</td>\n",
              "      <td>GetWeather</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          clean_text  ... labelencoder\n",
              "0                      find cinema nearest for films  ...            6\n",
              "1                  give the current series two stars  ...            4\n",
              "2                  find the good girl at movie house  ...            6\n",
              "3  please make reservations for three at kosher t...  ...            1\n",
              "4  what is the forecast for here one second from now  ...            2\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RfsD1LSpSag",
        "outputId": "0b044ede-99ee-4070-ecc0-4c6f031affe6"
      },
      "source": [
        "dummy_y.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13784, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4dq1macoeQC",
        "outputId": "e12e7035-f58c-4d6e-8fd4-2cc48d8a46e2"
      },
      "source": [
        "id_intention = 6\n",
        "print(\"Sprawdzenie poprawności LabelEncoder i to_categorical \\n\")\n",
        "print(\"Label - \", data_set_train[\"label\"].iloc[id_intention])\n",
        "print(\"LabelEncoder - \", data_set_train[\"labelencoder\"].iloc[id_intention])\n",
        "print()\n",
        "print(\"to_categorical - \", dummy_y[id_intention])\n",
        "print()\n",
        "print(\"return to LabelEncoder - \",np.argmax(dummy_y[id_intention], axis=-1))\n",
        "print(\"return to Label - \",labelencoder.inverse_transform([np.argmax(dummy_y[id_intention], axis=-1)]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sprawdzenie poprawności LabelEncoder i to_categorical \n",
            "\n",
            "Label -  BookRestaurant\n",
            "LabelEncoder -  1\n",
            "\n",
            "to_categorical -  [0. 1. 0. 0. 0. 0. 0.]\n",
            "\n",
            "return to LabelEncoder -  1\n",
            "return to Label -  ['BookRestaurant']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lZTDFgGoSmT"
      },
      "source": [
        "#### Zdefiniowanie X i y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWd9mEjfBAS2"
      },
      "source": [
        "X = data_set_train[\"clean_text\"]\n",
        "y = dummy_y"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jUlcX2npzFs",
        "outputId": "ac4fadda-82e1-4496-bb1b-c7bbc9c994f1"
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13784,), (13784, 7))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UAQ4RNONmda"
      },
      "source": [
        "\n",
        "#### `KerasClassifier` i `Grid Search Cross Validation`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vioWd2xMxru"
      },
      "source": [
        "`Grid Search Cross Validation`\n",
        "\n",
        "Tworzy siatkę nad przestrzenią wyszukiwania i ocenia model pod kątem wszystkich możliwych hiperparametrów w przestrzeni. Dobre w tym sensie, że jest proste i wyczerpujące. Z drugiej strony, może to być zbyt kosztowne w czasie obliczeń, jeśli przestrzeń poszukiwań jest duża (np. Bardzo wiele hiperparametrów).\n",
        "\n",
        "Przykład do zastosowania: https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A18D02x5sjFd"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCm-rbaus6QG"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaRWehbu_VCe"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hwih4PgGsS9k"
      },
      "source": [
        "from keras.layers import Dense, Activation, Embedding, Flatten, GlobalMaxPooling1D, Dropout, Conv1D"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnfPMuzQ-Cnq"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOcctLFPuKoa"
      },
      "source": [
        "def create_model(num_filters, kernel_size, vocab_size, embedding_dim, maxlen):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
        "    model.add(Conv1D(num_filters, kernel_size, activation='relu'))\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "    model.add(Dense(7, activation=\"softmax\")) \n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4tXfrhOxi7E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M23wynAYTodU"
      },
      "source": [
        "%%time\n",
        "\n",
        "# df z wynikami wszystkich RandomizedSearchCV\n",
        "wyniki = pd.DataFrame()\n",
        "wyniki\n",
        "\n",
        "from keras.wrappers.scikit_learn import KerasClassifier  \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "# Main settings\n",
        "# epochs = 20\n",
        "# embedding_dim = 100\n",
        "maxlen = 13\n",
        "\n",
        "# Run grid search for each source (yelp, amazon, imdb)\n",
        "# for source, frame in df.groupby('source'):\n",
        "# print('Running grid search for data set :', source)\n",
        "sentences = data_set_train[\"clean_text\"].values  \n",
        "y = dummy_y\n",
        "\n",
        "# Train-test split\n",
        "sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, y, test_size=0.25, random_state=1000)\n",
        "\n",
        "# Tokenize words\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(sentences_train)\n",
        "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
        "X_test = tokenizer.texts_to_sequences(sentences_test)\n",
        "\n",
        "# Adding 1 because of reserved 0 index\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Pad sequences with zeros\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
        "\n",
        "# Parameter grid for grid search\n",
        "param_grid = dict(num_filters=[32, 64, 128],\n",
        "                  kernel_size=[3, 5, 7],\n",
        "                  vocab_size=[vocab_size],\n",
        "                  embedding_dim=[100,200],\n",
        "                  maxlen=[maxlen],\n",
        "                  epochs = [30],   \n",
        "                  batch_size=[16,32,64]\n",
        "                  )\n",
        "\n",
        "\n",
        "model = KerasClassifier(build_fn=create_model,verbose=False)\n",
        "\n",
        "grid = GridSearchCV(estimator=model , param_grid=param_grid, n_jobs=-1, cv=3, verbose=10)\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "# Define early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "grid_result = grid.fit(X_train, y_train, validation_split=0.2, callbacks=[early_stopping])  #validation_split=0.2\n",
        "\n",
        "# Evaluate testing set\n",
        "test_accuracy = grid.score(X_test, y_test)\n",
        "grid_result.best_params_.update({\"best_score_\":grid_result.best_score_})\n",
        "wyniki = wyniki.append(grid_result.best_params_, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKQsYW_VTodZ"
      },
      "source": [
        "wyniki"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GNSbENU2NKh"
      },
      "source": [
        "print(\"#### RandomizedSearchCV\")\n",
        "print(wyniki.to_markdown())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0IdSKiJtzgd"
      },
      "source": [
        "#### Predykcja na zbiorze validacyjnym"
      ]
    }
  ]
}